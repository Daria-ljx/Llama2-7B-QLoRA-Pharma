{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "collapsed_sections": [
        "sM1SppXwqiw3"
      ],
      "provenance": []
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": "import os\nos.environ[\"HF_ENDPOINT\"]=\"https://hf-mirror.com\"",
      "metadata": {
        "id": "BwbU6SjiZT26"
      },
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "source": "!pip install -U -q peft bitsandbytes transformers accelerate trl datasets wandb",
      "metadata": {
        "id": "--8Z2c8sri7B"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n,To disable this warning, you can either:\n,\t- Avoid using `tokenizers` before the fork if possible\n,\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n,\u001b[0m"
        }
      ],
      "execution_count": 18
    },
    {
      "cell_type": "code",
      "source": "from transformers import AutoTokenizer, AutoModelForCausalLM, TrainingArguments, Trainer, BitsAndBytesConfig\nfrom peft import LoraConfig, get_peft_model, PeftModel, prepare_model_for_kbit_training\nfrom datasets import load_dataset\nfrom trl import DPOTrainer, DPOConfig\nimport torch\nimport os\nimport wandb\nfrom huggingface_hub import login\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom random import randrange",
      "metadata": {
        "id": "LTt-raa3r0Pg"
      },
      "outputs": [],
      "execution_count": 2
    },
    {
      "cell_type": "code",
      "source": "from dotenv import load_dotenv\nhftoken = load_dotenv(\"HF_TOKEN\")\nlogin(hftoken)",
      "metadata": {
        "id": "rlxkfpeEnUYg"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9957d36bac842a79d4025bd2abc6942",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "execution_count": 3
    },
    {
      "cell_type": "code",
      "source": "# 113df5e5bf10ba03e6203e2c35a0b78e160869ab\nwandb.login()",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdaria_ljx\u001b[0m (\u001b[33mdaria_ljx-university-of-malaya\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 4
    },
    {
      "cell_type": "code",
      "source": "# Config\n# =====================\nBASE_MODEL = \"meta-llama/Llama-2-7b-hf\"\nPRETRAIN_DATASET = \"Magaga23/Medical\" #5.45k\nFINETUNE_DATASET = \"FreedomIntelligence/Medical-R1-Distill-Data\" #22k\nREWARD_DATASET = \"Dahoas/synthetic-instruct-gptj-pairwise\" #33.1k\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nCHECKPOINT_INSTRUCTION = \"./checkpoint-instruction\"\nCHECKPOINT_DPO = \"./checkpoint-dpo\"\n\nSFT_ADAPTER = \"./instruction_sft_qlora\"\nDPO_ADAPTER = \"./dpo_qlora\"\n\nINSTRUCTION_MODEL_PUSH_TO_HUB_NAME = \"Darialjx2001/llama2-7b-qlora-instruction-sft\"\nDPO_MODEL_PUSH_TO_HUB_NAME = \"Darialjx2001/llama2-7b-qlora-dpo\"\n\nPROJECT_NAME = \"llama2-7b-qlora-pharma-preference\"\nos.environ[\"WANDB_PROJECT\"] = PROJECT_NAME\nos.environ[\"WANDB_DISABLED\"] = \"false\"",
      "metadata": {
        "id": "O7s8u3xbY23o"
      },
      "outputs": [],
      "execution_count": 5
    },
    {
      "cell_type": "code",
      "source": "# Initial Tokenizer\n# =====================\ntokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\nif tokenizer.pad_token is None:\n    tokenizer.pad_token = tokenizer.eos_token",
      "metadata": {
        "id": "tttnwwIyIvv9"
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "markdown",
      "source": "## Instruction Fine-tuning",
      "metadata": {
        "id": "N70HL3jAdugU"
      }
    },
    {
      "cell_type": "code",
      "source": "finetune_dataset = load_dataset(FINETUNE_DATASET,split=\"train\")",
      "metadata": {
        "id": "1KsCrPtpcYrG"
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": "print(finetune_dataset.column_names)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "['question', 'reasoning (reasoning_content)', 'response (content)']\n"
        }
      ],
      "execution_count": 8
    },
    {
      "cell_type": "code",
      "source": "def format_finetune_dataset(example):\n    text = (\n        \"Question: \" + \" \".join(str(example[\"question\"]).split()) + \"\\n\"\n        + \"Reasoning: \" + \" \".join(str(example[\"reasoning (reasoning_content)\"]).split()) + \"\\n\"\n        + \"Answer: \" + \" \".join(str(example[\"response (content)\"]).split())\n    )\n    return text",
      "metadata": {},
      "outputs": [],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": "print(format_finetune_dataset(finetune_dataset[randrange(len(finetune_dataset))]))",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Question: In the fracture of optic canal, which of the following pairs of structures is most likely to be damaged? A. Optic nerve and ophthalmic vein B. Ophthalmic vein and ophthalmic nerve C. Ophthalmic aery and optic nerve D. Ophthalmic nerve and optic nerve\n,Reasoning: Okay, so I need to figure out which structures are most likely damaged in a fracture of the optic canal. Let me start by recalling what's in the optic canal. From what I remember in anatomy, the optic canal is a passage in the sphenoid bone that connects the middle cranial fossa to the orbit. The main structures that pass through there are the optic nerve and the ophthalmic artery. The optic nerve is the second cranial nerve (CN II), responsible for vision. The ophthalmic artery is a branch of the internal carotid artery that supplies the eye and surrounding structures. Now, looking at the options given: A. Optic nerve and ophthalmic vein B. Ophthalmic vein and ophthalmic nerve C. Ophthalmic artery and optic nerve D. Ophthalmic nerve and optic nerve Wait, the optic canal contains the optic nerve and the ophthalmic artery. So option C is pairing those two. But I need to check if the ophthalmic vein also goes through there. Hmm. The superior orbital fissure is another opening where a lot of other structures pass, like the oculomotor nerve (CN III), trochlear nerve (CN IV), abducens nerve (CN VI), and the ophthalmic branch of the trigeminal nerve (V1). The ophthalmic veins, both superior and inferior, also pass through the superior orbital fissure, not the optic canal. So the ophthalmic vein isn't in the optic canal. The ophthalmic nerve is part of the trigeminal nerve (V1), which goes through the superior orbital fissure as well, not the optic canal. Therefore, options B and D mention the ophthalmic nerve, which isn't in the optic canal. Option A includes the ophthalmic vein, which also isn't in the optic canal. So the correct answer should be option C: Ophthalmic artery and optic nerve. But just to make sure I didn't mix up anything. Let me visualize the skull foramina. The optic canal is specifically for the optic nerve and ophthalmic artery. The superior orbital fissure is a larger opening that has multiple nerves and vessels, including the ophthalmic veins. So yes, a fracture in the optic canal would affect the structures within it, which are the optic nerve and ophthalmic artery. So answer C is correct.\n,Answer: In the event of a fracture of the optic canal, the structures most likely to be damaged are those contained within the canal itself. The optic canal, located in the sphenoid bone, transmits the **optic nerve (CN II)** and the **ophthalmic artery**. The ophthalmic artery is a branch of the internal carotid artery that supplies the eye, while the optic nerve is critical for vision. Other structures mentioned in the options, such as the **ophthalmic vein** and **ophthalmic nerve (V1)**, pass through the **superior orbital fissure** rather than the optic canal. Therefore, options involving these structures (A, B, D) are incorrect. **Correct Answer:** **C. Ophthalmic artery and optic nerve**\n"
        }
      ],
      "execution_count": 10
    },
    {
      "cell_type": "code",
      "source": "sampled_sft_dataset = finetune_dataset.shuffle(seed=42).select(range(1000))\nsft_data_samples = [format_finetune_dataset(sampled_sft_dataset[i]) for i in range(len(sampled_sft_dataset))]\n\n# Compute token counts\nlengths = [len(tokenizer(t).input_ids) for t in sft_data_samples]\n\n# Plot histogram\nplt.hist(lengths, bins=50, color='skyblue', edgecolor='black')\nplt.title('Token Length Distribution (First 1000 Samples)')\nplt.xlabel('Number of Tokens')\nplt.ylabel('Number of Samples')\nplt.show()\n\n# Print summary stats\navg_len = int(np.mean(lengths))\np95 = int(np.percentile(lengths, 95))\nprint(f\"Average token length: {avg_len}\")\nprint(f\"95% of samples have ≤ {p95} tokens\")",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Average token length: 2148\n,95% of samples have ≤ 5471 tokens\n"
        }
      ],
      "execution_count": 11
    },
    {
      "cell_type": "code",
      "source": "from itertools import chain\n\ndef clean_text(t: str):\n    # 移除所有换行、多空格、tab\n    return \" \".join(str(t).split())\n\ndef format_sample(example, max_reasoning_tokens=2048):\n    q = clean_text(example[\"question\"])\n    r = clean_text(example[\"reasoning (reasoning_content)\"])\n    a = clean_text(example[\"response (content)\"])\n\n    # tokenize reasoning\n    r_tokens = tokenizer(r).input_ids\n\n    # 截断 reasoning（避免 reasoning 太长吞掉 answer）\n    if len(r_tokens) > max_reasoning_tokens:\n        r_tokens = r_tokens[:max_reasoning_tokens]\n        r = tokenizer.decode(r_tokens, skip_special_tokens=True)\n        r = clean_text(r)   # 截断后再清洗\n\n    text = f\"Question: {q}\\nReasoning: {r}\\nAnswer: {a}\"\n    return text\n",
      "metadata": {},
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "format_sample(finetune_dataset[0])",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"Question: A 30-year-old female presents with a history of itching under her right breast and has an annular ring lesion upon examination. What is the most likely fungal organism causing this condition?\\nReasoning: Okay, so I need to figure out the most likely fungal organism causing an annular ring lesion under a 30-year-old female's right breast. Let me start by recalling what annular lesions usually indicate. An annular ring-shaped lesion is typical of certain skin infections. Since the question mentions a fungal organism, it's probably a type of dermatophyte infection. Dermatophytes are fungi that cause infections like tinea corporis (ringworm), tinea cruris (jock itch), and tinea pedis (athlete's foot). The location here is under the breast, which is a warm, moist area. That makes me think of tinea versicolor or maybe candidiasis, but tinea versicolor usually presents with discolored patches, not so much itching. Candidiasis can cause itching and redness in skin folds, but the annular lesion makes me lean more towards a dermatophyte. Wait, tinea corporis presents as an annular, scaly plaque with central clearing and an active red border. That fits the description here. The most common dermatophytes are Trichophyton, Microsporum, and Epidermophyton. Among these, Trichophyton species like T. rubrum are the most common cause of tinea corporis. But wait, the location is under the breast, which is a intertriginous area. Could it be tinea cruris instead? But tinea cruris usually affects the groin. However, dermatophytes can infect any body part, so maybe it's tinea corporis in an intertriginous area. Alternatively, Candida can cause infections in skin folds, presenting as red, macerated patches with satellite lesions. But Candida is a yeast, not a dermatophyte. The question specifies a fungal organism, which Candida is, but the annular ring makes me think more dermatophyte. However, sometimes Candida can have satellite lesions which might not be annular. Let me check some details. Tinea corporis typically has an annular appearance with central clearing and a scaly advancing border. The itching supports this. The location under the breast, being a warm and sweaty area, is a risk factor for fungal infections. So dermatophytes thrive there. The most common species causing tinea corporis is Trichophyton rubrum, followed by T. mentagrophytes and others. So the answer is likely Trichophyton rubrum. But I should also consider other possibilities. Could it be Microsporum? That's more common in tinea capitis. Epidermophyton causes tinea cruris and tinea pedis. Alternatively, is there a different fungal infection that presents with annular lesions? Pityriasis rosea is another annular rash, but that's viral and not fungal. So going back, the most probable is a dermatophyte, specifically Trichophyton species. Therefore, the most likely fungal organism is Trichophyton rubrum.\\nAnswer: The most likely fungal organism causing the annular ring lesion under the patient's breast is **Trichophyton rubrum**. **Key Points:** - **Annular lesion with itching** is classic for **tinea corporis** (ringworm), a dermatophyte infection. - **Location** (warm, moist skin fold) favors fungal growth, and dermatophytes like *Trichophyton* species thrive in such environments. - **Trichophyton rubrum** is the most common dermatophyte responsible for tinea corporis, characterized by scaly, erythematous plaques with central clearing and an active border. - Other possibilities like *Candida* (yeast) are less likely due to the annular morphology, which is more typical of dermatophytes. **Diagnosis:** Tinea corporis caused by *Trichophyton rubrum*. **Next Steps:** Confirm with potassium hydroxide (KOH) microscopy and treat with topical antifungals (e.g., clotrimazole, terbinafine).\""
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 39
    },
    {
      "cell_type": "code",
      "source": "format_finetune_dataset = finetune_dataset.map(\n    lambda e: {\"text\": format_sample(e)},\n    remove_columns=finetune_dataset.column_names\n)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7367055afb954854a6e53882b656694f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/22000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "execution_count": 41
    },
    {
      "cell_type": "code",
      "source": "def tokenize(examples):\n    return tokenizer(\n        examples[\"text\"],\n        truncation=False\n    )\n\ntokenized = format_finetune_dataset.map(tokenize, batched=True, remove_columns=[\"text\"])",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3d2031c147b54e858dbdce378b0813b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/22000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "execution_count": 42
    },
    {
      "cell_type": "code",
      "source": "def chunk_fn(examples, chunk_length=2048):\n\n    result = {}\n\n    for key, seqs in examples.items():\n        merged = list(chain(*seqs))\n        usable_len = (len(merged) // chunk_length) * chunk_length\n\n        if usable_len == 0:\n            result[key] = []\n        else:\n            result[key] = [\n                merged[i:i+chunk_length]\n                for i in range(0, usable_len, chunk_length)\n            ]\n\n    if \"input_ids\" in result:\n        result[\"labels\"] = [ids.copy() for ids in result[\"input_ids\"]]\n    else:\n        result[\"labels\"] = []\n\n    return result",
      "metadata": {},
      "outputs": [],
      "execution_count": 43
    },
    {
      "cell_type": "code",
      "source": "final_finetune_dataset = tokenized.map(\n    lambda x: chunk_fn(x, chunk_length=2048),\n    batched=True,\n    batch_size=100\n)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59dcf822c009415b81b284cbd57fa7b1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/22000 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "execution_count": 44
    },
    {
      "cell_type": "code",
      "source": "print(final_finetune_dataset)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Dataset({\n,    features: ['input_ids', 'attention_mask', 'labels'],\n,    num_rows: 17914\n,})\n"
        }
      ],
      "execution_count": 45
    },
    {
      "cell_type": "code",
      "source": "pip install -q flash-attn --no-build-isolation",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n,To disable this warning, you can either:\n,\t- Avoid using `tokenizers` before the fork if possible\n,\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n,\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b4a92c4ca10d42f18e60bcf8111d426c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ca409d78a640449e8c5d6241896cde7e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "execution_count": 25
    },
    {
      "cell_type": "code",
      "source": "from flash_attn import flash_attn_func",
      "metadata": {},
      "outputs": [],
      "execution_count": 26
    },
    {
      "cell_type": "code",
      "source": "bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_quant_type=\"nf4\",\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=True,\n)",
      "metadata": {
        "id": "PPCBmbc2jaN2"
      },
      "outputs": [],
      "execution_count": 46
    },
    {
      "cell_type": "code",
      "source": "model_instruction = AutoModelForCausalLM.from_pretrained(\n    BASE_MODEL,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    attn_implementation=\"flash_attention_2\"\n)",
      "metadata": {
        "id": "cvcR2OC-cYjX"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "de63e7203aba45c09fdd53680efc46a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 2 files:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a70084195e2a4a5bacfd2988aa7a3312",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "896e5c6dcf0740e79c3f159ec6bbb7ba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "Error while downloading from https://cas-bridge.xethub.hf.co/xet-bridge-us/64b0234d53bd91402e6ad49c/539e4f5b57902db78f25e629f0dc3cf6fbcc0aa988ba11759c94767f1e2c4a44?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20251204%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20251204T154400Z&X-Amz-Expires=3600&X-Amz-Signature=5dcb8f7ecdcc2e76af4977c27abebe21754144020a972f207a6923e56060da76&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=67e8c7931bd1638aa81b5da1&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model-00001-of-00002.safetensors%3B+filename%3D%22model-00001-of-00002.safetensors%22%3B&x-id=GetObject&Expires=1764866640&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc2NDg2NjY0MH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NGIwMjM0ZDUzYmQ5MTQwMmU2YWQ0OWMvNTM5ZTRmNWI1NzkwMmRiNzhmMjVlNjI5ZjBkYzNjZjZmYmNjMGFhOTg4YmExMTc1OWM5NDc2N2YxZTJjNGE0NCoifV19&Signature=gU0CB5tSP6tF2DbkHSYVzcwsinLWw7HAFHK9zE-bhzQbXyrcsQIO7uEiTTy9AhNXP9N-L18uKlJgZPa2UALf7z16jRyS2bg0X7iD-Z2U0D0cF48Hi3YKUf%7EyyRmi6QlhW8W5m0-nJcvt7MQ5FWzs23gS3c%7EKpsIu3zrm0-sdSwTTk1UzDxDx1R0saikNJDDznQrE2UGs7q2rUmtDS%7E9UvP9xRFD%7EqAnxSzdlnXL6bybsdrCTX2iCjMgdcU%7EOQ7m4qV17H6Fs7PTe4Pi5qmAIeU003vWQrWar4iE6CY8f87XRaXiL6qYkHud5Q1H68X5k2omXiEqZSGjsQkbIV1weOw__&Key-Pair-Id=K2L8F4GPSG1IFC: HTTPSConnectionPool(host='cas-bridge.xethub.hf.co', port=443): Read timed out.\n,Trying to resume download...\n"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "90fceb731f9247e8b2a4ceab2a6f9579",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8392597a2f04351a1a2a162cf51bd90",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "42e814cd5273404ebb8b31996a857345",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "execution_count": 47
    },
    {
      "cell_type": "code",
      "source": "# model_instruction.gradient_checkpointing_enable()\nmodel_instruction = prepare_model_for_kbit_training(model_instruction)",
      "metadata": {},
      "outputs": [],
      "execution_count": 48
    },
    {
      "cell_type": "code",
      "source": "instruction_lora_config = LoraConfig(\n    task_type=\"CAUSAL_LM\",\n    r=8,\n    lora_alpha=16,\n    lora_dropout=0.05,\n    target_modules=[\"q_proj\", \"v_proj\"]\n\n)\ninstruction_model = get_peft_model(model_instruction, instruction_lora_config)",
      "metadata": {
        "id": "UoATcGXDcYcr"
      },
      "outputs": [],
      "execution_count": 49
    },
    {
      "cell_type": "code",
      "source": "wandb.init(project=PROJECT_NAME, name=\"instruction-sft\")",
      "metadata": {
        "id": "pK9yCftwj5_w"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/root/wandb/run-20251204_234659-wz40zg2e</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/daria_ljx-university-of-malaya/llama2-7b-qlora-pharma-preference/runs/wz40zg2e' target=\"_blank\">instruction-sft</a></strong> to <a href='https://wandb.ai/daria_ljx-university-of-malaya/llama2-7b-qlora-pharma-preference' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/daria_ljx-university-of-malaya/llama2-7b-qlora-pharma-preference' target=\"_blank\">https://wandb.ai/daria_ljx-university-of-malaya/llama2-7b-qlora-pharma-preference</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/daria_ljx-university-of-malaya/llama2-7b-qlora-pharma-preference/runs/wz40zg2e' target=\"_blank\">https://wandb.ai/daria_ljx-university-of-malaya/llama2-7b-qlora-pharma-preference/runs/wz40zg2e</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Detected [huggingface_hub.inference] in use.\n,\u001b[34m\u001b[1mwandb\u001b[0m: Use W&B Weave for improved LLM call tracing. Install Weave with `pip install weave` then add `import weave` to the top of your script.\n,\u001b[34m\u001b[1mwandb\u001b[0m: For more information, check out the docs at: https://weave-docs.wandb.ai/\n"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/daria_ljx-university-of-malaya/llama2-7b-qlora-pharma-preference/runs/wz40zg2e?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f956875e510>"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 50
    },
    {
      "cell_type": "code",
      "source": "instruction_args = TrainingArguments(\n    output_dir=CHECKPOINT_INSTRUCTION,\n    learning_rate=2e-5,\n    per_device_train_batch_size=1, \n    gradient_accumulation_steps=4,\n    num_train_epochs=1,\n    bf16=True,\n    fp16=False,\n    logging_steps=100,\n    save_strategy=\"epoch\",\n    report_to=\"wandb\",\n    push_to_hub=True,\n    remove_unused_columns=False,\n    disable_tqdm=False,\n    optim=\"adamw_8bit\",\n)",
      "metadata": {
        "id": "CU3wc0wrcYPs"
      },
      "outputs": [],
      "execution_count": 54
    },
    {
      "cell_type": "code",
      "source": "trainer_instruction = Trainer(\n    model=instruction_model,\n    tokenizer=tokenizer,\n    args=instruction_args,\n    train_dataset=final_finetune_dataset\n)\ntrainer_instruction.train()\nwandb.finish()",
      "metadata": {
        "id": "8Z1D5UtEcX-0"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'instruction_args' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[60], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer_instruction \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39minstruction_model,\n\u001b[1;32m      3\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[0;32m----> 4\u001b[0m     args\u001b[38;5;241m=\u001b[39m\u001b[43minstruction_args\u001b[49m,\n\u001b[1;32m      5\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mfinal_finetune_dataset\n\u001b[1;32m      6\u001b[0m )\n\u001b[1;32m      7\u001b[0m trainer_instruction\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      8\u001b[0m wandb\u001b[38;5;241m.\u001b[39mfinish()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'instruction_args' is not defined"
          ]
        }
      ],
      "execution_count": 60
    },
    {
      "cell_type": "code",
      "source": "from huggingface_hub import create_repo, upload_folder\n\nrepo = \"Darialjx2001/llama2-7b-qlora-instruction-sft\"\n\nupload_folder(\n    folder_path=\"./checkpoint-instruction\",\n    repo_id=repo,\n    path_in_repo=\"checkpoint-instruction\",\n    repo_type=\"model\"\n)\n\nprint(\"Upload success!\")",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "869a9537387142a1ae6a19f3192b77a2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71011ef8a20443a99acc0f2bb84e9bec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload: |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Upload success!\n"
        }
      ],
      "execution_count": 57
    },
    {
      "cell_type": "code",
      "source": "instruction_model.save_pretrained(SFT_ADAPTER)\ninstruction_model.push_to_hub(INSTRUCTION_MODEL_PUSH_TO_HUB_NAME)\ntokenizer.push_to_hub(INSTRUCTION_MODEL_PUSH_TO_HUB_NAME)",
      "metadata": {
        "id": "Hr9cDIyjcX3G"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5fc9eea735d04f23b7806e0afe30b5a7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b980d8d1a1b149689a8aff2e8e89ed9c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload: |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5870624cead44df7ae21a0301d6207e9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/Darialjx2001/llama2-7b-qlora-instruction-sft/commit/cbbdfb2df5cd7c467681937bb5f3bd0f9bced7fe', commit_message='Upload tokenizer', commit_description='', oid='cbbdfb2df5cd7c467681937bb5f3bd0f9bced7fe', pr_url=None, repo_url=RepoUrl('https://hf-mirror.com/Darialjx2001/llama2-7b-qlora-instruction-sft', endpoint='https://hf-mirror.com', repo_type='model', repo_id='Darialjx2001/llama2-7b-qlora-instruction-sft'), pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 56
    },
    {
      "cell_type": "markdown",
      "source": "## DPO / Preference Alignment",
      "metadata": {
        "id": "FYr-OXwEeWol"
      }
    },
    {
      "cell_type": "code",
      "source": "reward_dataset = load_dataset(REWARD_DATASET, split=\"train\")",
      "metadata": {
        "id": "b6uXenH0cXv4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87158de4b03643079c4af11cc0c609a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "dataset_infos.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "18e51a99eec9484ead9928b3fdfb9e8e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "(…)-00000-of-00001-1e5d57b93c448e7a.parquet:   0%|          | 0.00/18.2M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c59672b25b14881a30d792c0e617dd5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/33143 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "execution_count": 57
    },
    {
      "cell_type": "code",
      "source": "print(reward_dataset.column_names)",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "['prompt', 'chosen', 'rejected']\n"
        }
      ],
      "execution_count": 58
    },
    {
      "cell_type": "code",
      "source": "def format_reward_dataset(example):\n    text = (\n        \"Prompt: \" + \" \".join(str(example[\"prompt\"]).split()) + \"\\n\"\n        + \"Chosen: \" + \" \".join(str(example[\"chosen\"]).split()) + \"\\n\"\n        + \"Rejected: \" + \" \".join(str(example[\"rejected\"]).split())\n    )\n    return text",
      "metadata": {},
      "outputs": [],
      "execution_count": 59
    },
    {
      "cell_type": "code",
      "source": "print(format_reward_dataset(reward_dataset[randrange(len(reward_dataset))]))",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Prompt: What do I need to know before going on a backpacking trip to Europe.\n,Chosen: Before heading off to a backpacking trip in Europe, it is important to make sure you have the right gear and supplies, a valid passport and appropriate visas, a clear understanding of your travel budget, and a working knowledge of the local language and customs. Additionally, make sure you check the weather forecast and have health insurance in case of an emergency.\n,Rejected: Well, backpacking isn't an unusual trip. Backpackaged trips to Europe are pretty common for people on business trips, and for people who are trying to travel between countries, and also sometimes for people who have been overseas and want to go back to their home. I guess the main question in these situations is: what's a good way to travel, and can you take a variety of different types of travel with you? Are you more concerned about particular routes, and how much time you have, plus you need to figure out the overall cost of a trip.\n"
        }
      ],
      "execution_count": 60
    },
    {
      "cell_type": "code",
      "source": "sampled_dpo_dataset = reward_dataset.shuffle(seed=42).select(range(2000))\ndpo_data_samples = [format_reward_dataset(sampled_dpo_dataset[i]) for i in range(len(sampled_dpo_dataset))]\n\n# Compute token counts\nlengths = [len(tokenizer(t).input_ids) for t in dpo_data_samples]\n\n# Plot histogram\nplt.hist(lengths, bins=50, color='skyblue', edgecolor='black')\nplt.title('Token Length Distribution (First 2000 Samples)')\nplt.xlabel('Number of Tokens')\nplt.ylabel('Number of Samples')\nplt.show()\n\n# Print summary stats\navg_len = int(np.mean(lengths))\np95 = int(np.percentile(lengths, 95))\nprint(f\"Average token length: {avg_len}\")\nprint(f\"95% of samples have ≤ {p95} tokens\")",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Average token length: 237\n,95% of samples have ≤ 412 tokens\n"
        }
      ],
      "execution_count": 61
    },
    {
      "cell_type": "code",
      "source": "def template_reward_dataset(sample):\n    sample['text'] = f\"{format_reward_dataset(sample)}{tokenizer.eos_token}\"\n    return sample\n\ndpo_dataset = reward_dataset.map(\n    template_reward_dataset,\n    remove_columns=list(reward_dataset.features)\n)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bf5f34ad5a3945d5a7f80e39c727d220",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/33143 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "execution_count": 62
    },
    {
      "cell_type": "code",
      "source": "def tokenize_function(examples):\n    return tokenizer(examples[\"text\"], truncation=False)\n\ntokenized_dpo_datasets = dpo_dataset.map(\n    tokenize_function,\n    batched=True,\n    remove_columns=[\"text\"]\n)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0b89d5355a6a430f93a385a215ad067e",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/33143 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "execution_count": 63
    },
    {
      "cell_type": "code",
      "source": "def chunk_dpo_dataset(examples, chunk_length=422):\n    result = {}\n    for key, lists in examples.items():\n        concatenated = list(chain(*lists))\n        total_length = len(concatenated)\n        usable_length = (total_length // chunk_length) * chunk_length\n        if usable_length == 0:\n            result[key] = [concatenated]  # 保留不足一个 chunk 的内容\n        else:\n            result[key] = [concatenated[i : i + chunk_length] for i in range(0, usable_length, chunk_length)]\n\n    if \"input_ids\" in result and len(result[\"input_ids\"]) > 0:\n        result[\"labels\"] = [list(x) for x in result[\"input_ids\"]]\n    else:\n        result[\"labels\"] = []\n\n    return result",
      "metadata": {},
      "outputs": [],
      "execution_count": 64
    },
    {
      "cell_type": "code",
      "source": "tokenized_dpo_dataset = tokenized_dpo_datasets.map(\n    lambda ex: chunk_dpo_dataset(ex, chunk_length=422),\n    batched=True,\n    batch_size=100\n)\nprint(tokenized_dpo_dataset)",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2a3cc415a21d461b9e2de9d9f064ac42",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/33143 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Dataset({\n,    features: ['input_ids', 'attention_mask', 'labels'],\n,    num_rows: 18637\n,})\n"
        }
      ],
      "execution_count": 65
    },
    {
      "cell_type": "code",
      "source": "# bnb_config = BitsAndBytesConfig(\n#     load_in_4bit=True,\n#     bnb_4bit_quant_type=\"nf4\",\n#     bnb_4bit_compute_dtype=torch.float16\n# )",
      "metadata": {
        "id": "DKTS1sfik2CY"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": "model_dpo = AutoModelForCausalLM.from_pretrained(\n    BASE_MODEL,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n    attn_implementation=\"flash_attention_2\"\n)",
      "metadata": {
        "id": "Q-bmfIcacXnO"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ee745bcafb948ff9336b5f8c7e98f34",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "execution_count": 66
    },
    {
      "cell_type": "code",
      "source": "model_dpo = PeftModel.from_pretrained(model_dpo,SFT_ADAPTER)\nmodel_dpo = model_dpo.merge_and_unload() #得到SFT全量模型",
      "metadata": {
        "id": "ScX8TVpFlBg0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "/root/miniconda3/lib/python3.12/site-packages/peft/tuners/lora/bnb.py:397: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n,  warnings.warn(\n"
        }
      ],
      "execution_count": 67
    },
    {
      "cell_type": "code",
      "source": "dpo_lora_config = LoraConfig(\n    r=8,\n    lora_alpha=16,\n    lora_dropout=0.05,\n    target_modules=[\"q_proj\", \"v_proj\"],\n    task_type=\"CAUSAL_LM\"\n)\ndpo_model = get_peft_model(model_dpo, dpo_lora_config)",
      "metadata": {
        "id": "hDEplFJmcXbC"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "/root/miniconda3/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n,  warnings.warn(\n"
        }
      ],
      "execution_count": 68
    },
    {
      "cell_type": "code",
      "source": "wandb.init(project=PROJECT_NAME, name=\"dpo\")",
      "metadata": {
        "id": "rtbTQSqjmk7x"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.23.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/root/wandb/run-20251205_051345-o6vxdzvc</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/daria_ljx-university-of-malaya/llama2-7b-qlora-pharma-preference/runs/o6vxdzvc' target=\"_blank\">dpo</a></strong> to <a href='https://wandb.ai/daria_ljx-university-of-malaya/llama2-7b-qlora-pharma-preference' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/daria_ljx-university-of-malaya/llama2-7b-qlora-pharma-preference' target=\"_blank\">https://wandb.ai/daria_ljx-university-of-malaya/llama2-7b-qlora-pharma-preference</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/daria_ljx-university-of-malaya/llama2-7b-qlora-pharma-preference/runs/o6vxdzvc' target=\"_blank\">https://wandb.ai/daria_ljx-university-of-malaya/llama2-7b-qlora-pharma-preference/runs/o6vxdzvc</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/daria_ljx-university-of-malaya/llama2-7b-qlora-pharma-preference/runs/o6vxdzvc?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7f956869faa0>"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 69
    },
    {
      "cell_type": "code",
      "source": "dpo_config = DPOConfig(\n    output_dir=CHECKPOINT_DPO,\n    learning_rate=2e-5,\n    per_device_train_batch_size=2, #2 RTX5090\n    gradient_accumulation_steps=4, #4 RTX5090\n    num_train_epochs=1,\n    beta=0.1,\n    logging_steps=50,\n    loss_type=\"sigmoid\",\n    report_to=\"wandb\",\n    push_to_hub=True,\n    remove_unused_columns=False,\n    disable_tqdm=False,\n    optim=\"adamw_8bit\",\n)",
      "metadata": {
        "id": "aJgIH8nXefEB"
      },
      "outputs": [],
      "execution_count": 70
    },
    {
      "cell_type": "code",
      "source": "dpo_trainer = DPOTrainer(\n    model=dpo_model,\n    ref_model=instruction_model,\n    args=dpo_config,\n    train_dataset=reward_dataset\n)\ndpo_trainer.train()",
      "metadata": {
        "id": "asc8T4_GeiVk"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "eb0dee7f3ebd4551aa4cf7baeff888c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting prompt in train dataset:   0%|          | 0/33143 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bb1bcaebb3f34c3e83f967d2a7e13778",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying chat template to train dataset:   0%|          | 0/33143 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "98c7a62670ce4f5a9afbc9c074cc4362",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizing train dataset:   0%|          | 0/33143 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'pad_token_id': None}.\n,/root/miniconda3/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n,  return fn(*args, **kwargs)\n,/root/miniconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n,  warnings.warn(\n"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4143' max='4143' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4143/4143 3:48:33, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>2.316000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.296700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.273600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.032100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.021800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.020100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.012300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.011300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.008500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.005000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.007500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.013600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.004800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.008500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.007800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.019100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.005000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.004400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.007700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.006000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.005100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.003100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1250</td>\n",
              "      <td>0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1300</td>\n",
              "      <td>0.002500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1350</td>\n",
              "      <td>0.042400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1400</td>\n",
              "      <td>0.004400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1450</td>\n",
              "      <td>0.003400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.016700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1550</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1600</td>\n",
              "      <td>0.003700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1650</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1700</td>\n",
              "      <td>0.010400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1750</td>\n",
              "      <td>0.000800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.001900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1850</td>\n",
              "      <td>0.001800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1900</td>\n",
              "      <td>0.001900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1950</td>\n",
              "      <td>0.002300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2050</td>\n",
              "      <td>0.009700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2100</td>\n",
              "      <td>0.001100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2150</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2200</td>\n",
              "      <td>0.000900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2250</td>\n",
              "      <td>0.001600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2300</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2350</td>\n",
              "      <td>0.003000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.001300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2450</td>\n",
              "      <td>0.008300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2550</td>\n",
              "      <td>0.000300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2600</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2650</td>\n",
              "      <td>0.003800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2700</td>\n",
              "      <td>0.003300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2750</td>\n",
              "      <td>0.002100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2800</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2850</td>\n",
              "      <td>0.001900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2900</td>\n",
              "      <td>0.010700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2950</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.003900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3050</td>\n",
              "      <td>0.011400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3100</td>\n",
              "      <td>0.006400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3150</td>\n",
              "      <td>0.008200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3200</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3250</td>\n",
              "      <td>0.004400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3300</td>\n",
              "      <td>0.011600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3350</td>\n",
              "      <td>0.006600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3400</td>\n",
              "      <td>0.001700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3450</td>\n",
              "      <td>0.000700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.000500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3550</td>\n",
              "      <td>0.002400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3600</td>\n",
              "      <td>0.001300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3650</td>\n",
              "      <td>0.002700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3700</td>\n",
              "      <td>0.002800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3750</td>\n",
              "      <td>0.002000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3800</td>\n",
              "      <td>0.003000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3850</td>\n",
              "      <td>0.001300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3900</td>\n",
              "      <td>0.002100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3950</td>\n",
              "      <td>0.001400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.000400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4050</td>\n",
              "      <td>0.002800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4100</td>\n",
              "      <td>0.002600</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "/root/miniconda3/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n,  return fn(*args, **kwargs)\n,/root/miniconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n,  warnings.warn(\n,/root/miniconda3/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n,  return fn(*args, **kwargs)\n,/root/miniconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n,  warnings.warn(\n,/root/miniconda3/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n,  return fn(*args, **kwargs)\n,/root/miniconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n,  warnings.warn(\n,/root/miniconda3/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n,  return fn(*args, **kwargs)\n,/root/miniconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n,  warnings.warn(\n,/root/miniconda3/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n,  return fn(*args, **kwargs)\n,/root/miniconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n,  warnings.warn(\n,/root/miniconda3/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n,  return fn(*args, **kwargs)\n,/root/miniconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n,  warnings.warn(\n,/root/miniconda3/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n,  return fn(*args, **kwargs)\n,/root/miniconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n,  warnings.warn(\n,/root/miniconda3/lib/python3.12/site-packages/torch/_dynamo/eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n,  return fn(*args, **kwargs)\n,/root/miniconda3/lib/python3.12/site-packages/torch/utils/checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n,  warnings.warn(\n"
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4143, training_loss=0.052312085742408275, metrics={'train_runtime': 13717.3775, 'train_samples_per_second': 2.416, 'train_steps_per_second': 0.302, 'total_flos': 0.0, 'train_loss': 0.052312085742408275, 'epoch': 1.0})"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 74
    },
    {
      "cell_type": "code",
      "source": "from huggingface_hub import create_repo, upload_folder\n\nrepo = \"Darialjx2001/llama2-7b-qlora-dpo\"\n\nupload_folder(\n    folder_path=\"./checkpoint-dpo\",\n    repo_id=repo,\n    path_in_repo=\"checkpoint-dpo\",\n    repo_type=\"model\"\n)\n\nprint(\"Upload success!\")\n",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7541db1b4f54434493a17385bbcef6eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "773ff6f801534d768dbfb8f22c07e929",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload: |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Upload success!\n"
        }
      ],
      "execution_count": 58
    },
    {
      "cell_type": "code",
      "source": "dpo_model.save_pretrained(DPO_ADAPTER)\ndpo_model.push_to_hub(DPO_MODEL_PUSH_TO_HUB_NAME)\ntokenizer.push_to_hub(DPO_MODEL_PUSH_TO_HUB_NAME)",
      "metadata": {
        "id": "rBEoQnU3enYo"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f78760ad94c1412dbc041a208785662d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing Files (0 / 0): |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f126fc3c05f94e13a3e7f37cb994af42",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "New Data Upload: |          |  0.00B /  0.00B            "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d0487c0bc5f4d39b8445a4a829e95a9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "CommitInfo(commit_url='https://huggingface.co/Darialjx2001/llama2-7b-qlora-dpo/commit/9ce5bcdc3155d33ba6a36d582229b039cc619d8c', commit_message='Upload tokenizer', commit_description='', oid='9ce5bcdc3155d33ba6a36d582229b039cc619d8c', pr_url=None, repo_url=RepoUrl('https://hf-mirror.com/Darialjx2001/llama2-7b-qlora-dpo', endpoint='https://hf-mirror.com', repo_type='model', repo_id='Darialjx2001/llama2-7b-qlora-dpo'), pr_revision=None, pr_num=None)"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 75
    },
    {
      "cell_type": "markdown",
      "source": "## Inference",
      "metadata": {
        "id": "dg52ijv9erBQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": "### Inference local adapter",
      "metadata": {
        "id": "evW31VqtpOtk"
      }
    },
    {
      "cell_type": "code",
      "source": "bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n)",
      "metadata": {
        "id": "4S1OoBt1pjBB"
      },
      "outputs": [],
      "execution_count": 6
    },
    {
      "cell_type": "code",
      "source": "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL)\ntokenizer.pad_token = tokenizer.eos_token",
      "metadata": {
        "id": "6sGmiiTFp4JD"
      },
      "outputs": [],
      "execution_count": 7
    },
    {
      "cell_type": "code",
      "source": "print(\"📌 Loading base model...\")\nbase_model = AutoModelForCausalLM.from_pretrained(\n    BASE_MODEL,\n    device_map=\"auto\",\n    quantization_config=bnb_config\n)",
      "metadata": {
        "id": "th0mhK_Epmf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "📌 Loading base model...\n"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1759bcc92ba647cd9dfc3e75fdd35944",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "execution_count": 9
    },
    {
      "cell_type": "code",
      "source": "def chat(model, prompt: str):\n  inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n  output = model.generate(\n      **inputs,\n      max_new_tokens=200,\n      temperature=0.7,\n      do_sample=True,\n  )\n  return tokenizer.decode(output[0], skip_special_tokens=True)",
      "metadata": {
        "id": "k0lsBFzMpmbS"
      },
      "outputs": [],
      "execution_count": 10
    },
    {
      "cell_type": "markdown",
      "source": "#### Instruction Model",
      "metadata": {
        "id": "YNC3Of19qZiA"
      }
    },
    {
      "cell_type": "code",
      "source": "instruction_model = PeftModel.from_pretrained(base_model, SFT_ADAPTER)\ninstruction_model.eval()",
      "metadata": {
        "id": "MouVhFbqpmdr"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(32000, 4096)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
              "              (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
              "              (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
              "              (act_fn): SiLUActivation()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 22
    },
    {
      "cell_type": "code",
      "source": "print(\"====== Base Response ======\")\nbase_model = AutoModelForCausalLM.from_pretrained(\n    BASE_MODEL,\n    quantization_config=bnb_config,\n    device_map=\"auto\"\n)\nprint(chat(base_model, \"What are the typical symptoms of seasonal allergic rhinitis?\"))",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "====== Base Response ======\n"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ad671580a4ae46b88d02bcd83d9c07de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "What are the typical symptoms of seasonal allergic rhinitis?\n, Hinweis: Bei einer allergischen Rhinitis wird in der Regel eine allergische Rhinitis-Sensibilisierungstestung durchgeführt.\n,The symptoms of seasonal allergic rhinitis vary from person to person, but may include:\n,Congestion in the nose\n,Sneezing and runny nose\n,Itchy nose, ears, mouth, or throat\n,In addition, some people may experience symptoms of asthma, such as shortness of breath, wheezing, or a tight chest.\n,The symptoms of seasonal allergic rhinitis are typically worse in the spring and fall, and tend to be less severe during the summer months.\n,What are the typical symptoms of perennial allergic rhinitis?\n,What are the typical symptoms of perennial allergic rhinitis? Hinweis: Bei einer allergischen Rhinitis wird in der\n"
        }
      ],
      "execution_count": 19
    },
    {
      "cell_type": "code",
      "source": "print(\"====== Instruction Response ======\")\nprint(chat(instruction_model, \"What are the typical symptoms of seasonal allergic rhinitis?\"))",
      "metadata": {
        "id": "k87cizyVp7WU"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "====== Instruction Response ======\n,What are the typical symptoms of seasonal allergic rhinitis?\n, Question: What are the typical symptoms of seasonal allergic rhinitis?\n,Reasoning: Okay, so I need to figure out the typical symptoms of seasonal allergic rhinitis. Let me start by recalling what I know about allergies. Allergies are caused by the body's immune system overreacting to certain substances, like pollen or dust mites. Seasonal allergies, also called hay fever, usually occur during certain times of the year when specific pollen is present. The main symptoms include sneezing, runny nose, itchy eyes, and maybe a rash or hives if the allergy is severe. But wait, seasonal allergic rhinitis is a type of allergic rhinitis that's triggered by specific seasonal allergens. So the symptoms should be related to those allergens. Let me list them out\n"
        }
      ],
      "execution_count": 24
    },
    {
      "cell_type": "markdown",
      "source": "#### DPO Model",
      "metadata": {
        "id": "gI6VxLp-qbqq"
      }
    },
    {
      "cell_type": "code",
      "source": "dpo_model = PeftModel.from_pretrained(base_model, DPO_ADAPTER)\ndpo_model.eval()",
      "metadata": {
        "id": "Brz1Mz3Cp7Ts"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(32000, 4096)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
              "              (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
              "              (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
              "              (act_fn): SiLUActivation()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 25
    },
    {
      "cell_type": "code",
      "source": "print(\"====== DPO Response ======\")\nprint(chat(dpo_model, \"What are the typical symptoms of seasonal allergic rhinitis?\"))",
      "metadata": {
        "id": "iKFo3pLYpmXi"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "====== DPO Response ======\n,What are the typical symptoms of seasonal allergic rhinitis?\n, everybody's symptoms of seasonal allergic rhinitis can vary depending on the individual, but some common symptoms include: runny or congested nose, itchy or watery eyes, sneezing, post-nasal drip, headaches, fatigue, and a general feeling of being unwell. In some cases, the symptoms may be worse in the mornings or after being outdoors.\n"
        }
      ],
      "execution_count": 26
    },
    {
      "cell_type": "markdown",
      "source": "### Inference hub adapter",
      "metadata": {
        "id": "sM1SppXwqiw3"
      }
    },
    {
      "cell_type": "code",
      "source": "!pip install transformers huggingface_hub peft torch",
      "metadata": {
        "id": "GCaEROJKqtEW"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n,To disable this warning, you can either:\n,\t- Avoid using `tokenizers` before the fork if possible\n,\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n,Requirement already satisfied: transformers in ./miniconda3/lib/python3.12/site-packages (4.57.3)\n,Requirement already satisfied: huggingface_hub in ./miniconda3/lib/python3.12/site-packages (0.36.0)\n,Requirement already satisfied: peft in ./miniconda3/lib/python3.12/site-packages (0.18.0)\n,Requirement already satisfied: torch in ./miniconda3/lib/python3.12/site-packages (2.5.1+cu124)\n,Requirement already satisfied: filelock in ./miniconda3/lib/python3.12/site-packages (from transformers) (3.16.1)\n,Requirement already satisfied: numpy>=1.17 in ./miniconda3/lib/python3.12/site-packages (from transformers) (2.1.3)\n,Requirement already satisfied: packaging>=20.0 in ./miniconda3/lib/python3.12/site-packages (from transformers) (23.2)\n,Requirement already satisfied: pyyaml>=5.1 in ./miniconda3/lib/python3.12/site-packages (from transformers) (6.0.2)\n,Requirement already satisfied: regex!=2019.12.17 in ./miniconda3/lib/python3.12/site-packages (from transformers) (2025.11.3)\n,Requirement already satisfied: requests in ./miniconda3/lib/python3.12/site-packages (from transformers) (2.32.5)\n,Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in ./miniconda3/lib/python3.12/site-packages (from transformers) (0.22.1)\n,Requirement already satisfied: safetensors>=0.4.3 in ./miniconda3/lib/python3.12/site-packages (from transformers) (0.7.0)\n,Requirement already satisfied: tqdm>=4.27 in ./miniconda3/lib/python3.12/site-packages (from transformers) (4.67.1)\n,Requirement already satisfied: fsspec>=2023.5.0 in ./miniconda3/lib/python3.12/site-packages (from huggingface_hub) (2024.10.0)\n,Requirement already satisfied: typing-extensions>=3.7.4.3 in ./miniconda3/lib/python3.12/site-packages (from huggingface_hub) (4.15.0)\n,Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in ./miniconda3/lib/python3.12/site-packages (from huggingface_hub) (1.2.0)\n,Requirement already satisfied: psutil in ./miniconda3/lib/python3.12/site-packages (from peft) (6.1.0)\n,Requirement already satisfied: accelerate>=0.21.0 in ./miniconda3/lib/python3.12/site-packages (from peft) (1.12.0)\n,Requirement already satisfied: networkx in ./miniconda3/lib/python3.12/site-packages (from torch) (3.4.2)\n,Requirement already satisfied: jinja2 in ./miniconda3/lib/python3.12/site-packages (from torch) (3.1.4)\n,Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./miniconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n,Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./miniconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n,Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./miniconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n,Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./miniconda3/lib/python3.12/site-packages (from torch) (9.1.0.70)\n,Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./miniconda3/lib/python3.12/site-packages (from torch) (12.4.5.8)\n,Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./miniconda3/lib/python3.12/site-packages (from torch) (11.2.1.3)\n,Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./miniconda3/lib/python3.12/site-packages (from torch) (10.3.5.147)\n,Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./miniconda3/lib/python3.12/site-packages (from torch) (11.6.1.9)\n,Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./miniconda3/lib/python3.12/site-packages (from torch) (12.3.1.170)\n,Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./miniconda3/lib/python3.12/site-packages (from torch) (2.21.5)\n,Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./miniconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n,Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./miniconda3/lib/python3.12/site-packages (from torch) (12.4.127)\n,Requirement already satisfied: triton==3.1.0 in ./miniconda3/lib/python3.12/site-packages (from torch) (3.1.0)\n,Requirement already satisfied: setuptools in ./miniconda3/lib/python3.12/site-packages (from torch) (69.5.1)\n,Requirement already satisfied: sympy==1.13.1 in ./miniconda3/lib/python3.12/site-packages (from torch) (1.13.1)\n,Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./miniconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch) (1.3.0)\n,Requirement already satisfied: MarkupSafe>=2.0 in ./miniconda3/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n,Requirement already satisfied: charset_normalizer<4,>=2 in ./miniconda3/lib/python3.12/site-packages (from requests->transformers) (2.0.4)\n,Requirement already satisfied: idna<4,>=2.5 in ./miniconda3/lib/python3.12/site-packages (from requests->transformers) (3.7)\n,Requirement already satisfied: urllib3<3,>=1.21.1 in ./miniconda3/lib/python3.12/site-packages (from requests->transformers) (2.1.0)\n,Requirement already satisfied: certifi>=2017.4.17 in ./miniconda3/lib/python3.12/site-packages (from requests->transformers) (2024.2.2)\n,\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n,\u001b[0m"
        }
      ],
      "execution_count": 27
    },
    {
      "cell_type": "code",
      "source": "!pip install -U bitsandbytes",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n,To disable this warning, you can either:\n,\t- Avoid using `tokenizers` before the fork if possible\n,\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "Looking in indexes: http://mirrors.aliyun.com/pypi/simple\n,Requirement already satisfied: bitsandbytes in ./miniconda3/lib/python3.12/site-packages (0.48.2)\n,Collecting bitsandbytes\n,  Downloading http://mirrors.aliyun.com/pypi/packages/a5/a8/26f7815b376b1d3dae615263471cb6d0d9f9792a472d5dab529502deac67/bitsandbytes-0.49.0-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n,\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n,\u001b[?25hRequirement already satisfied: torch<3,>=2.3 in ./miniconda3/lib/python3.12/site-packages (from bitsandbytes) (2.5.1+cu124)\n,Requirement already satisfied: numpy>=1.17 in ./miniconda3/lib/python3.12/site-packages (from bitsandbytes) (2.1.3)\n,Requirement already satisfied: packaging>=20.9 in ./miniconda3/lib/python3.12/site-packages (from bitsandbytes) (23.2)\n,Requirement already satisfied: filelock in ./miniconda3/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (3.16.1)\n,Requirement already satisfied: typing-extensions>=4.8.0 in ./miniconda3/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (4.15.0)\n,Requirement already satisfied: networkx in ./miniconda3/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (3.4.2)\n,Requirement already satisfied: jinja2 in ./miniconda3/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (3.1.4)\n,Requirement already satisfied: fsspec in ./miniconda3/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (2024.10.0)\n,Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in ./miniconda3/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\n,Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in ./miniconda3/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\n,Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in ./miniconda3/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\n,Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in ./miniconda3/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (9.1.0.70)\n,Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in ./miniconda3/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (12.4.5.8)\n,Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in ./miniconda3/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (11.2.1.3)\n,Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in ./miniconda3/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (10.3.5.147)\n,Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in ./miniconda3/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (11.6.1.9)\n,Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in ./miniconda3/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (12.3.1.170)\n,Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in ./miniconda3/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (2.21.5)\n,Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in ./miniconda3/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\n,Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in ./miniconda3/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (12.4.127)\n,Requirement already satisfied: triton==3.1.0 in ./miniconda3/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (3.1.0)\n,Requirement already satisfied: setuptools in ./miniconda3/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (69.5.1)\n,Requirement already satisfied: sympy==1.13.1 in ./miniconda3/lib/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (1.13.1)\n,Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./miniconda3/lib/python3.12/site-packages (from sympy==1.13.1->torch<3,>=2.3->bitsandbytes) (1.3.0)\n,Requirement already satisfied: MarkupSafe>=2.0 in ./miniconda3/lib/python3.12/site-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.2)\n,Installing collected packages: bitsandbytes\n,  Attempting uninstall: bitsandbytes\n,    Found existing installation: bitsandbytes 0.48.2\n,    Uninstalling bitsandbytes-0.48.2:\n,      Successfully uninstalled bitsandbytes-0.48.2\n,Successfully installed bitsandbytes-0.49.0\n,\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n,\u001b[0m"
        }
      ],
      "execution_count": 28
    },
    {
      "cell_type": "code",
      "source": "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\nfrom peft import PeftModel\nimport torch\nfrom huggingface_hub import login",
      "metadata": {
        "id": "-EHJtMJ-qj85"
      },
      "outputs": [],
      "execution_count": 29
    },
    {
      "cell_type": "code",
      "source": "from dotenv import load_dotenv\nhftoken = load_dotenv(\"HF_TOKEN\")\nlogin(hftoken)",
      "metadata": {
        "id": "iZ4FTFiRqxe6"
      },
      "outputs": [],
      "execution_count": 31
    },
    {
      "cell_type": "code",
      "source": "BASE_MODEL = \"meta-llama/Llama-2-7b-hf\"\nINSTRUCTION_MODEL_PUSH_TO_HUB_NAME = \"Darialjx2001/llama2-7b-qlora-instruction-sft\"\nDPO_MODEL_PUSH_TO_HUB_NAME = \"Darialjx2001/llama2-7b-qlora-dpo\"\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
      "metadata": {
        "id": "7ktBPRzIq0Yy"
      },
      "outputs": [],
      "execution_count": 32
    },
    {
      "cell_type": "code",
      "source": "tokenizer = AutoTokenizer.from_pretrained(BASE_MODEL, token=hftoken)\ntokenizer.pad_token = tokenizer.eos_token",
      "metadata": {
        "id": "yZ8P79Pgrw3Z"
      },
      "outputs": [],
      "execution_count": 33
    },
    {
      "cell_type": "code",
      "source": "bnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n)",
      "metadata": {
        "id": "Q2668VBirHRR"
      },
      "outputs": [],
      "execution_count": 34
    },
    {
      "cell_type": "code",
      "source": "print(\"📌 Loading base model from Hub...\")\nbase_model = AutoModelForCausalLM.from_pretrained(\n    BASE_MODEL,\n    device_map=\"auto\",\n    quantization_config=bnb_config\n)",
      "metadata": {
        "id": "7t5Q2ufYrJZA"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "📌 Loading base model from Hub...\n"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f382faaa8deb4644bf897e2f1189e443",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "execution_count": 35
    },
    {
      "cell_type": "code",
      "source": "def chat(model, prompt: str):\n  inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n  output = model.generate(\n      **inputs,\n      max_new_tokens=200,\n      temperature=0.7,\n      do_sample=True,\n  )\n  return tokenizer.decode(output[0], skip_special_tokens=True)",
      "metadata": {
        "id": "6OCj9T64ruI6"
      },
      "outputs": [],
      "execution_count": 36
    },
    {
      "cell_type": "code",
      "source": "print(\"====== Base Response ======\")\nprint(chat(base_model, \"What are the common symptoms of heart failure?\"))",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "====== Base Response ======\n,What are the common symptoms of heart failure?\n, Unterscheidung of congestive heart failure and other causes of shortness of breath\n, How is heart failure diagnosed?\n, What is the treatment for heart failure?\n, What is the outlook for a person with heart failure?\n,Heart failure is a condition in which the heart is unable to pump enough blood to meet the body's needs. The heart is a muscular pump that circulates blood throughout the body. Heart failure occurs when the heart muscle is unable to contract (squeeze) with enough force to pump blood to the body's organs. As a result, the heart is unable to pump enough blood to the body.\n,Heart failure can be caused by many conditions, including:\n,Infection of the heart (infective endocarditis)\n,Injury to the heart (for example, from a heart attack or severe infection)\n,Many of these conditions can be treated to prevent heart failure. Tre\n"
        }
      ],
      "execution_count": 37
    },
    {
      "cell_type": "markdown",
      "source": "#### Instruction model",
      "metadata": {
        "id": "MvLsKClTrqDp"
      }
    },
    {
      "cell_type": "code",
      "source": "instruction_model = PeftModel.from_pretrained(base_model, INSTRUCTION_MODEL_PUSH_TO_HUB_NAME)\ninstruction_model.eval()",
      "metadata": {
        "id": "GfTfEExnrMS8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(32000, 4096)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
              "              (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
              "              (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
              "              (act_fn): SiLUActivation()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 42
    },
    {
      "cell_type": "code",
      "source": "print(\"====== Instruction Response ======\")\nprint(chat(instruction_model, \"What are the common symptoms of heart failure?\"))",
      "metadata": {
        "id": "qD3SHxcnruFq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "====== Instruction Response ======\n,What are the common symptoms of heart failure?\n, Unterscheidung of the common symptoms of heart failure includes shortness of breath, swelling in the feet, ankles and legs, fatigue, weakness, difficulty breathing when lying down, irregular heartbeat, decreased ability to exercise, weight gain, decreased appetite, and increased need to urinate at night. Other symptoms may include coughing, chest pain, confusion, dizziness, and edema.\n"
        }
      ],
      "execution_count": 47
    },
    {
      "cell_type": "markdown",
      "source": "#### DPO model",
      "metadata": {
        "id": "oDM_lgu5rsad"
      }
    },
    {
      "cell_type": "code",
      "source": "dpo_model = PeftModel.from_pretrained(base_model, DPO_MODEL_PUSH_TO_HUB_NAME)\ndpo_model.eval()",
      "metadata": {
        "id": "dNvYfSYLsTDB"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PeftModelForCausalLM(\n",
              "  (base_model): LoraModel(\n",
              "    (model): LlamaForCausalLM(\n",
              "      (model): LlamaModel(\n",
              "        (embed_tokens): Embedding(32000, 4096)\n",
              "        (layers): ModuleList(\n",
              "          (0-31): 32 x LlamaDecoderLayer(\n",
              "            (self_attn): LlamaAttention(\n",
              "              (q_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (k_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "              (v_proj): lora.Linear4bit(\n",
              "                (base_layer): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "                (lora_dropout): ModuleDict(\n",
              "                  (default): Dropout(p=0.05, inplace=False)\n",
              "                )\n",
              "                (lora_A): ModuleDict(\n",
              "                  (default): Linear(in_features=4096, out_features=8, bias=False)\n",
              "                )\n",
              "                (lora_B): ModuleDict(\n",
              "                  (default): Linear(in_features=8, out_features=4096, bias=False)\n",
              "                )\n",
              "                (lora_embedding_A): ParameterDict()\n",
              "                (lora_embedding_B): ParameterDict()\n",
              "                (lora_magnitude_vector): ModuleDict()\n",
              "              )\n",
              "              (o_proj): Linear4bit(in_features=4096, out_features=4096, bias=False)\n",
              "            )\n",
              "            (mlp): LlamaMLP(\n",
              "              (gate_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
              "              (up_proj): Linear4bit(in_features=4096, out_features=11008, bias=False)\n",
              "              (down_proj): Linear4bit(in_features=11008, out_features=4096, bias=False)\n",
              "              (act_fn): SiLUActivation()\n",
              "            )\n",
              "            (input_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "            (post_attention_layernorm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "          )\n",
              "        )\n",
              "        (norm): LlamaRMSNorm((4096,), eps=1e-05)\n",
              "        (rotary_emb): LlamaRotaryEmbedding()\n",
              "      )\n",
              "      (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": 44
    },
    {
      "cell_type": "code",
      "source": "print(\"====== DPO Response ======\")\nprint(chat(dpo_model, \"What are the common symptoms of heart failure?\"))",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "====== DPO Response ======\n,What are the common symptoms of heart failure?\n, hopefully the common symptoms of heart failure are shortness of breath, swelling in the ankles and feet, fatigue, difficulty breathing, coughing or wheezing, chest pain or pressure, rapid or irregular heartbeat, loss of appetite, nausea or vomiting, and a feeling of fullness in the chest.\n"
        }
      ],
      "execution_count": 53
    }
  ]
}